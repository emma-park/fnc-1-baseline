{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from this import s\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from feature_engineering import refuting_features, polarity_features, hand_features, gen_or_load_feats\n",
    "from feature_engineering import word_overlap_features\n",
    "from utils.dataset import DataSet\n",
    "from utils.generate_test_splits import kfold_split, get_stances_for_folds\n",
    "from utils.score import report_score, LABELS, score_submission\n",
    "\n",
    "from utils.system import parse_params, check_version\n",
    "from csv import DictReader\n",
    "import pandas\n",
    "\n",
    "import gensim\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from tqdm import tqdm\n",
    "from nltk import tokenize\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense,Dropout,Embedding,CuDNNLSTM,Bidirectional, Flatten\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENT_LEN = 50\n",
    "MAX_VOCAB_SIZE = 40000\n",
    "EMBEDDING_DIM = 100\n",
    "BATCH_SIZE = 200\n",
    "N_EPOCHS = 10\n",
    "REGULARIZER_HYPERPARAM = 0.01\n",
    "\n",
    "hyperparam = {\n",
    "    'batch_size': 200,\n",
    "    'max_vocab_size': 20000,\n",
    "    'max_length': 44,\n",
    "    'embedding_dim': 100,\n",
    "    'dropout_rate': 0.3,\n",
    "    'learning_rate': 0.1,\n",
    "    'n_epochs': 10,\n",
    "}\n",
    "\n",
    "\n",
    "def generate_features(stances,dataset,name):\n",
    "    h, b, y = [],[],[]\n",
    "\n",
    "    for stance in stances:\n",
    "        y.append(LABELS.index(stance['Stance']))\n",
    "        h.append(stance['Headline'])\n",
    "        b.append(dataset.articles[stance['Body ID']])\n",
    "\n",
    "    X_overlap = gen_or_load_feats(word_overlap_features, h, b, \"features/overlap.\"+name+\".npy\")\n",
    "    X_refuting = gen_or_load_feats(refuting_features, h, b, \"features/refuting.\"+name+\".npy\")\n",
    "    X_polarity = gen_or_load_feats(polarity_features, h, b, \"features/polarity.\"+name+\".npy\")\n",
    "    X_hand = gen_or_load_feats(hand_features, h, b, \"features/hand.\"+name+\".npy\")\n",
    "\n",
    "    X = np.c_[X_hand, X_polarity, X_refuting, X_overlap]\n",
    "    return X,y\n",
    "\n",
    "def formatData(tokenizer, x):\n",
    "    word_seq = [text_to_word_sequence(sent) for sent in x]\n",
    "    X = tokenizer.texts_to_sequences([' '.join(seq[:MAX_SENT_LEN]) for seq in word_seq])\n",
    "    X = pad_sequences(X, maxlen=MAX_SENT_LEN, padding='post', truncating='post')\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset\n",
      "Total stances: 49972\n",
      "Total bodies: 1683\n",
      "Reading dataset\n",
      "Total stances: 25413\n",
      "Total bodies: 904\n"
     ]
    }
   ],
   "source": [
    "# check_version()\n",
    "# parse_params()\n",
    "\n",
    "#Load the training dataset and generate folds\n",
    "d = DataSet()\n",
    "folds,hold_out = kfold_split(d,n_folds=10)\n",
    "fold_stances, hold_out_stances = get_stances_for_folds(d,folds,hold_out)\n",
    "\n",
    "# Load the competition dataset\n",
    "competition_dataset = DataSet(\"competition_test\")\n",
    "X_competition, y_competition = generate_features(competition_dataset.stances, competition_dataset, \"competition\")\n",
    "\n",
    "h, b = [], []\n",
    "for stance in competition_dataset.stances:\n",
    "    h.append(stance['Headline'])\n",
    "    b.append(stance['Body ID'])\n",
    "\n",
    "answers = {'Headline': h, 'Body ID': b, 'Stance': []}\n",
    "\n",
    "Xs = dict()\n",
    "ys = dict()\n",
    "\n",
    "# Load/Precompute all features now\n",
    "X_holdout,y_holdout = generate_features(hold_out_stances,d,\"holdout\")\n",
    "for fold in fold_stances:\n",
    "    Xs[fold],ys[fold] = generate_features(fold_stances[fold],d,str(fold))\n",
    "\n",
    "\n",
    "best_score = 0\n",
    "best_fold = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = d.articles.values()\n",
    "sentences = []\n",
    "for article in articles:\n",
    "    sentences += tokenize.sent_tokenize(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build tokenizer\n",
    "word_seq = [text_to_word_sequence(sent) for sent in sentences]\n",
    "token = Tokenizer(num_words=hyperparam['max_vocab_size'])\n",
    "token.fit_on_texts([' '.join(seq[:hyperparam['max_length']]) for seq in word_seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400001it [00:30, 13094.16it/s]\n"
     ]
    }
   ],
   "source": [
    "#build glove embedding vector\n",
    "embedding_vector = {}\n",
    "f = open('./glove/glove.6B.100d.txt')\n",
    "for line in tqdm(f):\n",
    "    value = line.split(' ')\n",
    "    word = value[0]\n",
    "    coef = np.array(value[1:],dtype = 'float32')\n",
    "    embedding_vector[word] = coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27235/27235 [00:00<00:00, 81218.21it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(token.word_index.items()) + 1\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size,100))\n",
    "for word,i in tqdm(token.word_index.items()):\n",
    "    embedding_value = embedding_vector.get(word)\n",
    "    if embedding_value is not None:\n",
    "        embedding_matrix[i] = embedding_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(\n",
    "    input_dim=len(embedding_matrix),\n",
    "    output_dim=hyperparam['embedding_dim'],\n",
    "    weights=[embedding_matrix],\n",
    "    input_length=hyperparam['max_length'],\n",
    "    trainable = False\n",
    "))\n",
    "model.add(Bidirectional(LSTM(75, return_sequences=False, name='Bidrectional_lstm_layer1')))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32,activation = 'relu'))\n",
    "model.add(Dropout(rate=0.8, name='dropout_1')) # Can try varying dropout rates, in paper suggest 0.2\n",
    "# model.add(Dense(1,activation = 'sigmoid'))\n",
    "model.add(Dense(4,activation='softmax'))\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "182/182 [==============================] - 64s 349ms/step - loss: 0.3450 - accuracy: 0.8774 - val_loss: 0.3572 - val_accuracy: 0.8550\n",
      "Epoch 2/10\n",
      "182/182 [==============================] - 62s 342ms/step - loss: 0.3421 - accuracy: 0.8777 - val_loss: 0.3616 - val_accuracy: 0.8545\n",
      "Epoch 3/10\n",
      "182/182 [==============================] - 60s 329ms/step - loss: 0.3415 - accuracy: 0.8785 - val_loss: 0.3736 - val_accuracy: 0.8516\n",
      "Epoch 4/10\n",
      "182/182 [==============================] - 50s 274ms/step - loss: 0.3393 - accuracy: 0.8781 - val_loss: 0.3474 - val_accuracy: 0.8584\n",
      "Epoch 5/10\n",
      "182/182 [==============================] - 51s 280ms/step - loss: 0.3370 - accuracy: 0.8792 - val_loss: 0.3435 - val_accuracy: 0.8560\n",
      "Epoch 6/10\n",
      "182/182 [==============================] - 48s 265ms/step - loss: 0.3373 - accuracy: 0.8790 - val_loss: 0.3480 - val_accuracy: 0.8589\n",
      "Epoch 7/10\n",
      "182/182 [==============================] - 56s 307ms/step - loss: 0.3340 - accuracy: 0.8801 - val_loss: 0.3596 - val_accuracy: 0.8545\n",
      "Epoch 8/10\n",
      "182/182 [==============================] - 55s 300ms/step - loss: 0.3324 - accuracy: 0.8802 - val_loss: 0.3521 - val_accuracy: 0.8579\n",
      "Epoch 9/10\n",
      "145/182 [======================>.......] - ETA: 11s - loss: 0.3313 - accuracy: 0.8808"
     ]
    }
   ],
   "source": [
    "# Classifier for each fold\n",
    "for fold in fold_stances:\n",
    "    ids = list(range(len(folds)))\n",
    "    del ids[fold]\n",
    "\n",
    "    X_train = np.vstack(tuple([Xs[i] for i in ids]))\n",
    "    y_train = np.hstack(tuple([ys[i] for i in ids]))\n",
    "\n",
    "    X_test = Xs[fold]\n",
    "    y_test = ys[fold]\n",
    "    \n",
    "    X_val = np.array(X_test[:(len(X_test) // 2)])\n",
    "    y_val = np.array(y_test[:(len(X_test) // 2)])\n",
    "    x_test = X_test[(len(X_test) // 2):]\n",
    "    y_test = y_test[(len(X_test) // 2):]\n",
    "    \n",
    "#     new model\n",
    "    model.fit(X_train, y_train,\n",
    "              batch_size=hyperparam['batch_size'],\n",
    "              epochs=10,\n",
    "              validation_data=(X_val, y_val),\n",
    "              verbose=1)\n",
    "#     clf = GradientBoostingClassifier(n_estimators=200, random_state=14128, verbose=True)\n",
    "#     clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 6 was - 0.773792305467168\n"
     ]
    }
   ],
   "source": [
    "predicted = [LABELS[np.argmax(a, axis = 0)] for a in model.predict(x_test)]\n",
    "actual = [LABELS[int(a)] for a in y_test]\n",
    "\n",
    "fold_score, _ = score_submission(actual, predicted)\n",
    "max_fold_score, _ = score_submission(actual, actual)\n",
    "\n",
    "score = fold_score/max_fold_score\n",
    "\n",
    "print(\"Score for fold \"+ str(fold) + \" was - \" + str(score))\n",
    "if score > best_score:\n",
    "    best_score = score\n",
    "    best_fold = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores on the dev set\n",
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |    63     |     0     |    614    |    85     |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |     9     |     0     |    140    |    13     |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |    33     |     0     |   1584    |    183    |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |     7     |     0     |    155    |   6736    |\n",
      "-------------------------------------------------------------\n",
      "Score: 3530.0 out of 4448.5\t(79.35259076093065%)\n",
      "Scores on the test set\n",
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |    100    |     0     |   1510    |    293    |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |    23     |     0     |    435    |    239    |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |    123    |     0     |   3644    |    697    |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |     8     |     0     |    527    |   17814   |\n",
      "-------------------------------------------------------------\n",
      "Score: 8720.25 out of 11651.25\t(74.84390086900547%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "74.84390086900547"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run on Holdout set and report the final score on the holdout set\n",
    "predicted = [LABELS[np.argmax(a, axis = 0)] for a in best_fold.predict(X_holdout)]\n",
    "actual = [LABELS[int(a)] for a in y_holdout]\n",
    "\n",
    "print(\"Scores on the dev set\")\n",
    "report_score(actual,predicted)\n",
    "\n",
    "#Run on competition dataset\n",
    "predicted = [LABELS[np.argmax(a, axis = 0)] for a in best_fold.predict(X_competition)]\n",
    "answers[\"Stance\"] = predicted\n",
    "answers = pandas.DataFrame(answers)\n",
    "answers.to_csv('answer.csv', index=False, encoding='utf-8')\n",
    "actual = [LABELS[int(a)] for a in y_competition]\n",
    "print(\"Scores on the test set\")\n",
    "report_score(actual,predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
